{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking heritage: Day 1, Afternoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is GLAM data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"438\"\n",
       "            src=\"https://slides.com/wragge/hh2020-glam-data/embed?token=S804-5hr\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x106409890>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://slides.com/wragge/hh2020-glam-data/embed?token=S804-5hr', 600, 438)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Activities\n",
    "\n",
    "### Sources of GLAM data\n",
    "\n",
    "I've started compiling a [list of GLAM data sources](https://glam-workbench.github.io/glam-data-list/), including APIs, and downloadbale collections of text and images. There's also an associated [list of GLAM datasets](https://glam-workbench.github.io/glam-datasets-from-gov-portals/) that I've harvested from government open data portals – including more than 600 CSV files! There's also a [searchable database of the GLAM datasets](https://ozglam-datasets.glitch.me/data/glam-datasets-from-gov-portals) on Glitch.\n",
    "\n",
    "There are also many notebooks in the GLAM Workbench to help you obtain data – for example by harvesting details of newspaper articles from Trove, screenscraping metadata from the National Archives of Australia, or downloading collection data via the National Museum API. Take some time to explore all the possible data sources, and think about what interests you.\n",
    "\n",
    "### GLAM CSV Explorer\n",
    "\n",
    "The list of [GLAM datasets from government open data portals](https://glam-workbench.github.io/glam-datasets-from-gov-portals/) helps us get an overview of  data being made available by GLAM organisations around the country. But it's still difficult to get a sense of **what's in** all those datasets. It's one of those *why* questions again – why would I be interested in this?\n",
    "\n",
    "To help give potential users a peek inside all those datasets, I made the GLAM CSV Explorer. You select a dataset from the dropdown list, and the code analyses the CSV, visualising the results.\n",
    "\n",
    "The CSV Explorer is made to be run in Appmode. But because of the way this server is configured, I can't just point you to a version running in Appmode. However, we can create a link by using the following bit of code. Just run it, and then click on the link it creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook.notebookapp import list_running_servers\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Get current running servers\n",
    "servers = list_running_servers()\n",
    "# Get the current base url\n",
    "base_url = next(servers)['base_url']\n",
    "app_url = f'{base_url}apps/hackingheritage2020/csv-explorer/csv-explorer.ipynb'\n",
    "display(HTML(f'<a href=\"{app_url}\">Open CSV Explorer in Appmode</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Click on the cell above and run it (yep **Shift+Enter** again). Click on the link it creates.\n",
    "* Once the CSV Explorer loads, try selecting a dataset from the dropdown lists.\n",
    "* Spend some time exploring the available datasets. What can you discover? What surprises are there? What questions would you like to pursue further?\n",
    "\n",
    "<div class=\"alert alert-info\"><img src=\"../images/hhicon.png\" width=\"50px\" style=\"vertical-align: bottom; margin-right: 10px;\">Remember to share your discoveries in the Slack #discussion channel.</div>\n",
    "\n",
    "* Of course, the CSV Explorer has to make a lot of assumptions and guesses about the data, and these won't always be helpful. Where does it do well? And we're does it fall down? \n",
    "* If you're curious, you can click on the 'Edit App' button to peek at the code underneath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring GLAM data\n",
    "\n",
    "Below you'll find a series of notebooks exploring different types of GLAM data. Work through them as best you can with your trusty **Shift+Enter**. Try out some of the suggestions and challenges along the way. Once again, don't worry about the specifics of the code, just get a sense of the possibilities.\n",
    "\n",
    "#### 1. Some manual CSV exploration\n",
    "\n",
    "The GLAM CSV Explorer works by analysing each column in the dataset – what sorts of values does it contain, what is the range of values, how many are there? Whenever we come across a new source of structured data it can be useful to explore its size and shape.\n",
    "\n",
    "Here's a notebook that downloads one of the CSV files from the GLAM data list and uses Pandas to extract some basic information. Open up the notebook and work your way through.\n",
    "\n",
    "* [The size and shape of a CSV file](../building-blocks/size-and-shape-of-structured-data.ipynb)\n",
    "\n",
    "\n",
    "#### 2. Counting words\n",
    "\n",
    "A lot of the text available from GLAM organisations is unstructured, and often the result of OCR processes that are far from perfect. But while it might not be organised into rows and columns like CSV files, text has it's own structures – words, sentences, names, parts of speech. There are a variety of tools we can use to explore these implicit structures. Let's start with the simplest and count some words.\n",
    "\n",
    "* [Counting words in text](../building-blocks/counting-words-in-text.ipynb)\n",
    "\n",
    "On a much larger scale, we can use semi-structured text from Commonwealth Hansard to find out how many words were spoken each year in Parliament, and by who!\n",
    "\n",
    "* [Convert a year of Parliament into a dataframe for analysis](../australian-commonwealth-hansard/convert-a-year-to-dataframe.ipynb)\n",
    "\n",
    "#### 3. Viewing images\n",
    "\n",
    "Many GLAM organisations make images available for download or viewing online. Who doesn't like looking at photos? The Museum of Victoria provides a 'random' sort option in its API, so with a small amount of code we can create a random image viewer. Give it a spin!\n",
    "\n",
    "* [A random item from the Museum of Victoria's collections](../building-blocks/museumvic-random-item.ipynb)\n",
    "\n",
    "#### 4. From text to data and back again\n",
    "\n",
    "Remember too that digitised publications and archives are often also available as images. This morning you saw one way of getting a high resolution image from Trove's newspapers, but what if you don't want the whole page, just the article? Here's another hack!\n",
    "\n",
    "* [Save a Trove newspaper article as an image](../trove-newspapers/Save-Trove-newspaper-article-as-image.ipynb)\n",
    "\n",
    "The notebook above uses positional data from the OCR process, scraped from the article's web page, to get it's coordinates on the page. Here's another notebook that gets OCRd text from a poster, and then tries to use the positional information to save images of all the separate letters (not wholly successfully). It's very much an experiment, but an interesting one...\n",
    "\n",
    "* [Use OCR to get text from an image (and images from text?)](../building-blocks/use-ocr-to-get-text-from-an-image.ipynb)\n",
    "\n",
    "#### 5. Those busy text correctors\n",
    "\n",
    "Earlier I talked about Trove newspaper correction statistics as GLAM activity data. Here's a little demo that creates a corrections ticker – keeping you updated with the total number of corrections.\n",
    "\n",
    "* [Trove newspapers corrections ticker](../trove-newspapers/Create-a-Trove-corrections-ticker.ipynb)\n",
    "\n",
    "If you'd like a bit more detail, here's a notebook that analyses the correction data:\n",
    "\n",
    "* [Analysing OCR corrections](trove-newspapers/Analysing_OCR_corrections.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
